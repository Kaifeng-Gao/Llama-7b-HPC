{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d1374e-d9bd-41c7-b7cf-2eb57393ffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 30 18:44:09 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  | 00000000:31:00.0 Off |                  Off |\n",
      "| 30%   24C    P8              16W / 230W |      2MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7cc16e-506f-446d-9c65-624820f390f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "\n",
    "# TODO: Replace model path with your own\n",
    "# The path should look like `models--<organization>--<model-name>/snapshots/<snapshot-id>` under the cache directory defined when downloading the model\n",
    "model_path = \"/home/sds262_kg797/palmer_scratch/Llama-2-7b-chat-hf/models--meta-llama--Llama-2-7b-chat-hf/snapshots/92011f62d7604e261f748ec0cfe6329f31193e33\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ad282-1ced-48da-a72e-fa112c77fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b56732bc064cff8dd46bee8d36e6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfcbae3-548b-4c04-ba2e-848cf5596e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about Yale University.\n",
      "Yale University is a private Ivy League research university located in New Haven, Connecticut. Founded in 1701, Yale is one of the oldest institutions of higher learning in the United States and is widely regarded as one of the most prestigious universities in the world.\n",
      "\n",
      "Yale has a long and storied history, with many notable alumni, including five U.S. presidents, 17 U.S. Supreme Court justices, and countless leaders in fields such as business, politics, and the arts. The university is known for its academic excellence, with programs in the arts and sciences, law, medicine, and divinity. Yale is also home to the Yale University Library, which is one of the largest and most extensive library collections in the world.\n",
      "\n",
      "Yale has a strong research focus and has made significant contributions to various fields, including the discovery of the structure of DNA, the development of the polio vaccine, and the creation of the first computer. The university is also known for its cultural and artistic achievements, including the Yale University Art Gallery, the Yale Repertory Theatre, and the Yale Whiffenpoofs, a renowned a cappella group.\n",
      "\n",
      "Yale has a diverse and vibrant student body, with students from all 50 states and over 100 countries. The university offers a range of undergraduate and graduate programs, including the Bachelor of Arts, the Bachelor of Science in Engineering, and the Master of Arts and Master of Science degrees. Yale also has a strong athletic program, with teams competing in the Ivy League and NCAA Division I.\n",
      "\n",
      "Overall, Yale University is a world-renowned institution that offers students a rigorous academic experience, opportunities for research and creative expression, and a rich cultural and social environment.\n",
      "CPU times: user 16.3 s, sys: 6.13 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"Tell me about Yale\"\n",
    "\n",
    "model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**model_inputs)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2eca61-f3d4-452b-b249-7078f95cf050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
